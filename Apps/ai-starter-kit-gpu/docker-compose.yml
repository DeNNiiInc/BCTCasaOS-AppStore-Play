name: ai-starter-kit-gpu

# 限制日志大小，防止日志占满磁盘
x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

# n8n 基础配置（复用）
x-n8n: &service-n8n
  image: n8nio/n8n:latest
  networks:
    - ai-starter-kit
  init: true
  logging: *default-logging
  environment:
    # 基础配置
    - TZ=${TZ:-UTC}
    - DB_TYPE=postgresdb
    - DB_POSTGRESDB_HOST=postgres
    - DB_POSTGRESDB_USER=${POSTGRES_USER:-root}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD:-password}
    - DB_POSTGRESDB_DATABASE=${POSTGRES_DB:-n8n}

    # 隐私/安全与稳定性
    - N8N_DIAGNOSTICS_ENABLED=false
    - N8N_PERSONALIZATION_ENABLED=false
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:-super-secret-key}
    - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET:-even-more-secret}
    - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
    - N8N_RUNNERS_ENABLED=true
    - N8N_SECURE_COOKIE=${N8N_SECURE_COOKIE:-true}

    # 外部访问设置（可按需覆盖）
    - WEBHOOK_URL=${WEBHOOK_URL:-https://your-domain.com}
    - N8N_PROTOCOL=${N8N_PROTOCOL:-https}
    - N8N_PORT=${N8N_PORT:-5678}
    - N8N_HOST=${N8N_HOST:-your-domain.com}

    # LLM 服务地址
    - OLLAMA_HOST=ollama:11434

services:

  # n8n 服务
  n8n:
    <<: *service-n8n
    hostname: n8n
    container_name: ai-starter-kit-n8n
    restart: unless-stopped
    user: "1000:1000" # 使用非 root 运行
    ports:
      - "5678:5678"
    volumes:
      - /DATA/AppData/ai-starter-kit/n8n_storage:/home/node/.n8n
      - /DATA/AppData/ai-starter-kit/n8n/backup:/backup
      - /DATA/AppData/ai-starter-kit/shared:/data/shared
    depends_on:
      postgres:
        condition: service_healthy
      n8n-import:
        condition: service_completed_successfully
    stop_grace_period: 30s
    healthcheck:
      test:
        - CMD-SHELL
        - curl -sf http://localhost:5678/healthz || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        reservations:
          memory: 128M

  # n8n 导入服务，用以导入凭据和工作流（启动时执行一次）
  n8n-import:
    <<: *service-n8n
    hostname: n8n-import
    container_name: ai-starter-kit-n8n-import
    entrypoint: /bin/sh
    working_dir: /home/node
    command:
      - "-c"
      - >
        set -e;
        rm -rf repo &&
        git clone --depth 1 "${STARTER_KIT_REPO:-https://github.com/n8n-io/self-hosted-ai-starter-kit.git}" repo &&
        if [ -n "${STARTER_KIT_REF:-}" ]; then
          git -C repo fetch --depth 1 origin "${STARTER_KIT_REF}" &&
          git -C repo checkout "${STARTER_KIT_REF}";
        fi &&
        mkdir -p /home/node/backup &&
        cp -r repo/n8n/backup/* /home/node/backup &&
        n8n import:credentials --separate --input=/home/node/backup/credentials &&
        n8n import:workflow --separate --input=/home/node/backup/workflows
    environment:
      - STARTER_KIT_REPO=${STARTER_KIT_REPO:-https://github.com/n8n-io/self-hosted-ai-starter-kit.git}
      # 可选：指定固定提交/标签，保证可重复（例如：v1.0.0 或具体 commit sha）
      - STARTER_KIT_REF=${STARTER_KIT_REF:-}
    volumes:
      - /DATA/AppData/ai-starter-kit/n8n/backup:/home/node/backup
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"
    healthcheck:
      test: ["CMD-SHELL", "test -d /home/node/backup && test -n \"$(ls -A /home/node/backup 2>/dev/null)\""]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # n8n 数据库
  postgres:
    image: postgres:16-alpine
    hostname: ai-starter-kit-postgres
    networks:
      - ai-starter-kit
    init: true
    logging: *default-logging
    restart: unless-stopped
    environment:
      - TZ=${TZ:-UTC}
      - POSTGRES_USER=${POSTGRES_USER:-root}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password}
      - POSTGRES_DB=${POSTGRES_DB:-n8n}
    volumes:
      - /DATA/AppData/ai-starter-kit/postgres_storage:/var/lib/postgresql/data
    healthcheck:
      test:
        - CMD-SHELL
        - pg_isready -h localhost -U "${POSTGRES_USER:-root}" -d "${POSTGRES_DB:-n8n}"
      interval: 5s
      timeout: 5s
      retries: 20
      start_period: 10s
    container_name: ai-starter-kit-postgres

  # 向量数据库
  qdrant:
    image: qdrant/qdrant:latest
    hostname: qdrant
    container_name: ai-starter-kit-qdrant
    networks:
      - ai-starter-kit
    init: true
    logging: *default-logging
    restart: unless-stopped
    ports:
      - "6333:6333"
    environment:
      - TZ=${TZ:-UTC}
      - QDRANT__TELEMETRY_DISABLED=${QDRANT__TELEMETRY_DISABLED:-true}
    volumes:
      - /DATA/AppData/ai-starter-kit/qdrant_storage:/qdrant/storage
    healthcheck:
      test:
        - CMD-SHELL
        - curl -sf http://localhost:6333/ready || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

  # ollama 服务（NVIDIA GPU）
  ollama:
    image: ollama/ollama:latest
    container_name: ai-starter-kit-ollama
    networks:
      - ai-starter-kit
    init: true
    logging: *default-logging
    restart: unless-stopped
    ports:
      - 11434:11434
    environment:
      - TZ=${TZ:-UTC}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-24h}
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-2}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-1}
      # NVIDIA 运行时变量（常见环境需要）
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
    volumes:
      - /DATA/AppData/ai-starter-kit/ollama_storage:/root/.ollama
    healthcheck:
      test:
        - CMD-SHELL
        - curl -sf http://localhost:11434/api/tags || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    # Compose (非 Swarm) 场景下多数环境同样会尊重该配置；确保宿主机已安装 NVIDIA Container Toolkit
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ollama pull 服务，用以初始化时拉取模型
  ollama-pull-llama:
    image: ollama/ollama:latest
    container_name: ai-starter-kit-ollama-pull-llama
    networks:
      - ai-starter-kit
    init: true
    logging: *default-logging
    volumes:
      - /DATA/AppData/ai-starter-kit/ollama_storage:/root/.ollama
    entrypoint: /bin/sh
    environment:
      - OLLAMA_HOST=ollama:11434
    command:
      - "-c"
      - >
        sleep 3;
        ollama pull llama3.2 &&
        ollama pull deepseek-r1:1.5b &&
        ollama pull qwen2.5:latest &&
        ollama pull qwen3:4b
    depends_on:
      ollama:
        condition: service_healthy
    restart: "no"

networks:
  ai-starter-kit:
    name: ai-starter-kit
    driver: bridge

x-casaos:
  architectures:
    - amd64
    - arm64
  main: n8n
  store_app_id: ai-starter-kit-gpu
  author: Cp0204
  category: Beyond Cloud Technology
  description:
    en_us: "Self-hosted AI Starter Kit is an open-source Docker Compose template designed to swiftly initialize a comprehensive local AI and low-code development environment. It combines the self-hosted n8n platform with a curated list of compatible AI products and components to quickly get started with building self-hosted AI workflows."
    zh_cn: "Self-hosted AI Starter Kit 是一个开源的 Docker Compose 模板，旨在快速初始化一个全面的本地 AI 和低代码开发环境。它将自托管的 n8n 平台与精选的兼容 AI 产品和组件列表相结合，以快速开始构建自托管的 AI 工作流程。"
  developer: n8n-io
  icon: https://filedn.com/ltuKYRdlbf4BG2UkSiE8r7b/GITHUB/CASAOS/BCTCasaOS-AppStore-Play-main/Apps/ai-starter-kit/icon.png
  screenshot_link:
    - https://filedn.com/ltuKYRdlbf4BG2UkSiE8r7b/GITHUB/CASAOS/BCTCasaOS-AppStore-Play-main/Apps/ai-starter-kit/screenshot-1.png
  tagline:
    en_us: Self-hosted AI starter kit
    zh_cn: 自托管 AI 启动套件
  # thumbnail: https://filedn.com/ltuKYRdlbf4BG2UkSiE8r7b/GITHUB/CASAOS/BCTCasaOS-AppStore-Play-main/Apps/ai-starter-kit/thumbnail.png
  tips:
    before_install:
      en_us: "If this is the first time you’re running the workflow, you may need to wait until Ollama finishes downloading Llama3.2. You can inspect the docker console logs to check on the progress."
      zh_cn: "如果这是您第一次启动此套件，您可能需要等待 Ollama 完成 Llama3.2 的下载。您可以检查 Docker 控制台日志以查看进度。"
  title:
    en_us: n8n Al Kit [NVIDIA]
  index: /
  port_map: "5678"
